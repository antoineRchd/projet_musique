# ğŸ—ï¸ Architecture Kafka Producer-Consumer - Projet Spotify

Architecture complÃ¨te pour le traitement des donnÃ©es Spotify avec Kafka.

## ğŸ¯ Vue d'ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  KAFKA PRODUCER â”‚â”€â”€â”€â–¶â”‚      KAFKA      â”‚â”€â”€â”€â–¶â”‚  KAFKA CONSUMER â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  â€¢ Download     â”‚    â”‚  Topic:         â”‚    â”‚  â€¢ Analytics    â”‚
â”‚  â€¢ Transform    â”‚    â”‚  spotify-tracks â”‚    â”‚  â€¢ Dashboard    â”‚
â”‚  â€¢ Publish      â”‚    â”‚                 â”‚    â”‚  â€¢ Export       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                         â”‚                         â”‚
       â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kaggle API    â”‚    â”‚  Zookeeper      â”‚    â”‚  Output Files   â”‚
â”‚   (Dataset)     â”‚    â”‚  (Coordination) â”‚    â”‚  (CSV/JSON)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Composants

### ğŸ“¤ **Kafka Producer** (`kafka-producer`)

**RÃ´le :** Acquisition et publication des donnÃ©es

**FonctionnalitÃ©s :**
- âœ… TÃ©lÃ©chargement automatique du dataset Spotify (114k tracks)
- âœ… Chargement et validation des donnÃ©es CSV
- âœ… Publication par lots (1000 messages/lot)
- âœ… VÃ©rification des donnÃ©es existantes (Ã©vite les doublons)
- âœ… Gestion d'erreurs robuste avec retry
- âœ… Logs dÃ©taillÃ©s de progression

**Configuration :**
```yaml
environment:
  - KAFKA_BOOTSTRAP_SERVERS=kafka:9093
  - KAFKA_TOPIC=spotify-tracks
  - PRODUCER_MODE=true
  - BATCH_SIZE=1000
  - DELAY_BETWEEN_BATCHES=1
```

**DÃ©marrage :** Une seule fois au dÃ©marrage du systÃ¨me

### ğŸ“¥ **Kafka Consumer** (`kafka-consumer`)

**RÃ´le :** Consommation et analyse des donnÃ©es

**FonctionnalitÃ©s :**
- âœ… Consommation en temps rÃ©el des messages Kafka
- âœ… Analytics avancÃ©es (genres, artistes, audio features)
- âœ… Dashboard temps rÃ©el (mise Ã  jour toutes les 30s)
- âœ… Sauvegarde automatique (CSV, JSON)
- âœ… ArrÃªt gracieux (Ctrl+C)
- âœ… Monitoring des performances

**Configuration :**
```yaml
environment:
  - KAFKA_BOOTSTRAP_SERVERS=kafka:9093
  - KAFKA_TOPIC=spotify-tracks
  - CONSUMER_GROUP=spotify-analytics-group
  - OUTPUT_DIR=/app/output
  - BATCH_SIZE=100
  - STATS_INTERVAL=30
```

**DÃ©marrage :** Continue en arriÃ¨re-plan (restart: unless-stopped)

## ğŸš€ DÃ©marrage complet

```bash
# 1. DÃ©marrer toute l'infrastructure
docker-compose up -d

# 2. VÃ©rifier les logs du producer (charge les donnÃ©es)
docker-compose logs -f kafka-producer

# 3. VÃ©rifier les logs du consumer (traite les donnÃ©es)
docker-compose logs -f kafka-consumer

# 4. AccÃ©der Ã  l'interface Kafka UI
# http://localhost:8090
```

## ğŸ“Š Flux de donnÃ©es

### **1. Phase d'acquisition (Producer)**
```
Kaggle API â”€â”€â–¶ Download â”€â”€â–¶ CSV Load â”€â”€â–¶ JSON Transform â”€â”€â–¶ Kafka Publish
    â”‚              â”‚           â”‚              â”‚               â”‚
    8.17MB     114k tracks  21 columns    JSON format    1000/batch
```

### **2. Phase de traitement (Consumer)**
```
Kafka Poll â”€â”€â–¶ Track Process â”€â”€â–¶ Analytics â”€â”€â–¶ Dashboard â”€â”€â–¶ File Save
    â”‚              â”‚               â”‚           â”‚            â”‚
Real-time     Feature Extract  Stats Calc   Display    CSV/JSON
```

## ğŸµ Structure des donnÃ©es

### **Message Kafka :**
```json
{
  "track_id": "5SuOikwiRyPMVoIQDJUgSV",
  "track_name": "Comedy",
  "artists": "Gen Hoshino",
  "album_name": "Comedy",
  "popularity": 73,
  "duration_ms": 230666,
  "explicit": false,
  "danceability": 0.676,
  "energy": 0.461,
  "valence": 0.715,
  "tempo": 87.917,
  "track_genre": "acoustic",
  "timestamp": 1751539166,
  "record_id": 0
}
```

### **Analytics gÃ©nÃ©rÃ©es :**
- **Summary** : MÃ©triques globales
- **Top Genres** : Classification musicale
- **Top Artists** : PopularitÃ© des artistes
- **Audio Features** : CaractÃ©ristiques moyennes

## ğŸ”„ Gestion des erreurs

### **Producer :**
- Retry automatique (5 tentatives)
- Skip des messages dÃ©faillants
- Logs dÃ©taillÃ©s des erreurs
- Graceful shutdown

### **Consumer :**
- Timeout non-bloquant (1 seconde)
- Continue processing en cas d'erreur
- Sauvegarde pÃ©riodique des donnÃ©es
- Signal handling (SIGINT, SIGTERM)

## ğŸ“ˆ Monitoring

### **MÃ©triques Producer :**
- Messages publiÃ©s/Ã©checs
- Vitesse de publication
- Progression du dataset
- Statut connexion Kafka

### **MÃ©triques Consumer :**
- Tracks traitÃ©es
- Vitesse de traitement
- Genres/Artistes uniques
- Features audio moyennes

## ğŸŒ Interfaces

### **Kafka UI :** http://localhost:8090
- Topics et partitions
- Messages en temps rÃ©el
- Consumer groups
- MÃ©triques Kafka

### **Hadoop NameNode :** http://localhost:9870
- HDFS status
- Cluster information

### **Spark UI :** http://localhost:8080
- Applications Spark
- Jobs et stages

## ğŸ›ï¸ Configuration avancÃ©e

### **Kafka Topics :**
```bash
# CrÃ©er topic avec plus de partitions
KAFKA_CREATE_TOPICS: "spotify-tracks:3:1"

# Modifier retention
KAFKA_LOG_RETENTION_HOURS=72
```

### **Performance :**
```yaml
# Producer
BATCH_SIZE=2000
DELAY_BETWEEN_BATCHES=0.5

# Consumer  
BATCH_SIZE=500
STATS_INTERVAL=10
```

## ğŸ”§ Maintenance

### **RedÃ©marrer services :**
```bash
# Producer seulement
docker-compose restart kafka-producer

# Consumer seulement  
docker-compose restart kafka-consumer

# Tout redÃ©marrer
docker-compose restart
```

### **Nettoyer les donnÃ©es :**
```bash
# Supprimer volumes (donnÃ©es perdues)
docker-compose down -v

# Nettoyer les fichiers de sortie
rm -rf output/*
```

## ğŸ¯ Cas d'usage

### **Analytics temps rÃ©el :**
- Dashboard live des donnÃ©es musicales
- Monitoring de tendances
- DÃ©tection d'anomalies

### **Data Science :**
- Analyse des prÃ©fÃ©rences musicales  
- Machine Learning sur audio features
- Recommandations personnalisÃ©es

### **Big Data Pipeline :**
- Ingestion de donnÃ©es massives
- Traitement distribuÃ© avec Spark
- Stockage HDFS pour analytics batch

## ğŸš§ Extensions possibles

1. **Multiple Consumers** : DiffÃ©rents types d'analyses
2. **Stream Processing** : Spark Streaming integration  
3. **Machine Learning** : ModÃ¨les prÃ©dictifs en temps rÃ©el
4. **APIs REST** : Exposition des analytics
5. **Visualizations** : Dashboards interactifs
6. **Alerting** : Notifications sur Ã©vÃ©nements 