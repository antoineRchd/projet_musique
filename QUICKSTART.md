# ğŸµ Guide de dÃ©marrage rapide - Spotify Dataset Kafka

Ce guide vous permettra de rapidement intÃ©grer le dataset Spotify dans Kafka.

## ğŸš€ DÃ©marrage rapide

### 1. DÃ©marrer l'infrastructure

```bash
docker-compose up -d
```

### 2. Publier le dataset Spotify dans Kafka

```bash
./run_producer.sh
```

### 3. Tester la consommation

```bash
./test_consumer.sh
```

## ğŸ“ Ã‰tapes dÃ©taillÃ©es

### Ã‰tape 1 : PrÃ©paration

1. **Installer les dÃ©pendances**
   ```bash
   pip install -r requirements.txt
   ```

2. **DÃ©marrer les services Docker**
   ```bash
   docker-compose up -d
   ```

   Services dÃ©marrÃ©s :
   - âœ… Zookeeper (port 2181)
   - âœ… Kafka (port 9092)
   - âœ… Hadoop NameNode (port 9870)
   - âœ… Hadoop DataNode
   - âœ… Spark Master (port 8080)

### Ã‰tape 2 : Publication des donnÃ©es

Le producteur va automatiquement :
1. ğŸ“¥ TÃ©lÃ©charger le dataset Spotify depuis Kaggle
2. ğŸ“Š Charger les donnÃ©es CSV
3. ğŸš€ Publier chaque piste dans Kafka (topic: `spotify-tracks`)

```bash
cd producer
python test_local.py
```

### Ã‰tape 3 : VÃ©rification

Tester que les donnÃ©es sont bien publiÃ©es :

```bash
cd producer
python consumer_test.py --max-messages 5
```

## ğŸ¯ Utilisation avancÃ©e

### Configuration personnalisÃ©e

Modifier les paramÃ¨tres dans `producer/producer.py` :

```python
# Topic Kafka
KAFKA_TOPIC = "spotify-tracks"

# Taille des lots
BATCH_SIZE = 1000

# DÃ©lai entre les lots
DELAY_BETWEEN_BATCHES = 1
```

### Consommation avec Spark

Les donnÃ©es peuvent Ãªtre consommÃ©es par Spark Streaming :

```python
from pyspark.sql import SparkSession
from pyspark.sql.types import *

spark = SparkSession.builder \
    .appName("SpotifyStreaming") \
    .getOrCreate()

# Lire depuis Kafka
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "spotify-tracks") \
    .load()

# DÃ©coder les donnÃ©es JSON
spotify_df = df.select(
    col("key").cast("string"),
    from_json(col("value").cast("string"), spotify_schema).alias("data")
).select("key", "data.*")
```

## ğŸ® Interfaces web

Une fois dÃ©marrÃ©, vous pouvez accÃ©der Ã  :

- **Spark UI** : http://localhost:8080
- **Hadoop NameNode** : http://localhost:9870

## ğŸ”§ DÃ©pannage

### Kafka ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker-compose logs kafka

# RedÃ©marrer les services
docker-compose restart
```

### Erreur de tÃ©lÃ©chargement Kaggle

1. VÃ©rifier la configuration de l'API Kaggle
2. S'assurer d'avoir acceptÃ© les conditions du dataset

### Erreur de mÃ©moire

Pour de gros datasets :
- RÃ©duire `BATCH_SIZE`
- Augmenter `DELAY_BETWEEN_BATCHES`
- Augmenter la mÃ©moire Docker

## ğŸ“Š DonnÃ©es du dataset

Le dataset Spotify contient :
- **MÃ©tadonnÃ©es** : nom, artiste, album, popularitÃ©
- **CaractÃ©ristiques audio** : danceability, energy, valence, tempo
- **Informations techniques** : durÃ©e, clÃ©, mode, etc.

## ğŸ”„ Prochaines Ã©tapes

1. **Traitement en temps rÃ©el** avec Spark Streaming
2. **Stockage** dans HDFS
3. **Analyse** avec des jobs Spark
4. **Visualisation** des donnÃ©es

## ğŸ†˜ Support

En cas de problÃ¨me :
1. VÃ©rifier les logs : `docker-compose logs [service]`
2. Consulter la documentation dans `producer/README.md`
3. Tester individuellement chaque composant 